#include "std.h"

std_Decimal std_Decimal_defVal = 0;

std_Decimal std_Decimal_fromStr(fr_Env __env, sys_Str s, sys_Bool checked) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }
std_Decimal std_Decimal_toDecimal(fr_Env __env, sys_Num f) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }
void std_Decimal_privateMake(fr_Env __env, std_Decimal_ref __self) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); }
sys_Bool std_Decimal_equals(fr_Env __env, std_Decimal_ref __self, sys_Obj_null obj) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }
sys_Int std_Decimal_compare(fr_Env __env, std_Decimal_ref __self, sys_Obj obj) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }
sys_Int std_Decimal_hash(fr_Env __env, std_Decimal_ref __self) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }
std_Decimal std_Decimal_negate(fr_Env __env, std_Decimal_ref __self) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }
std_Decimal std_Decimal_increment(fr_Env __env, std_Decimal_ref __self) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }
std_Decimal std_Decimal_decrement(fr_Env __env, std_Decimal_ref __self) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }
std_Decimal std_Decimal_mult(fr_Env __env, std_Decimal_ref __self, std_Decimal b) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }
std_Decimal std_Decimal_multInt(fr_Env __env, std_Decimal_ref __self, sys_Int b) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }
std_Decimal std_Decimal_multFloat(fr_Env __env, std_Decimal_ref __self, sys_Float b) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }
std_Decimal std_Decimal_div(fr_Env __env, std_Decimal_ref __self, std_Decimal b) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }
std_Decimal std_Decimal_divInt(fr_Env __env, std_Decimal_ref __self, sys_Int b) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }
std_Decimal std_Decimal_divFloat(fr_Env __env, std_Decimal_ref __self, sys_Float b) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }
std_Decimal std_Decimal_mod(fr_Env __env, std_Decimal_ref __self, std_Decimal b) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }
std_Decimal std_Decimal_modInt(fr_Env __env, std_Decimal_ref __self, sys_Int b) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }
std_Decimal std_Decimal_modFloat(fr_Env __env, std_Decimal_ref __self, sys_Float b) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }
std_Decimal std_Decimal_plus(fr_Env __env, std_Decimal_ref __self, std_Decimal b) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }
std_Decimal std_Decimal_plusInt(fr_Env __env, std_Decimal_ref __self, sys_Int b) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }
std_Decimal std_Decimal_plusFloat(fr_Env __env, std_Decimal_ref __self, sys_Float b) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }
std_Decimal std_Decimal_minus(fr_Env __env, std_Decimal_ref __self, std_Decimal b) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }
std_Decimal std_Decimal_minusInt(fr_Env __env, std_Decimal_ref __self, sys_Int b) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }
std_Decimal std_Decimal_minusFloat(fr_Env __env, std_Decimal_ref __self, sys_Float b) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }
std_Decimal std_Decimal_abs(fr_Env __env, std_Decimal_ref __self) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }
std_Decimal std_Decimal_min(fr_Env __env, std_Decimal_ref __self, std_Decimal that) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }
std_Decimal std_Decimal_max(fr_Env __env, std_Decimal_ref __self, std_Decimal that) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }
sys_Str std_Decimal_toStr(fr_Env __env, std_Decimal_ref __self) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }
sys_Str std_Decimal_toCode(fr_Env __env, std_Decimal_ref __self) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }
sys_Int std_Decimal_toInt(fr_Env __env, std_Decimal_ref __self) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }
sys_Float std_Decimal_toFloat(fr_Env __env, std_Decimal_ref __self) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }
sys_Str std_Decimal_toLocale(fr_Env __env, std_Decimal_ref __self, sys_Str_null pattern) { FR_SET_ERROR_ALLOC(sys_UnsupportedErr); return 0; }

